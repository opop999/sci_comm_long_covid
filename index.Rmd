---
title: "Long Covid:"
subtitle: "What is the buzz all about?"
author: "Ondrej Pekacek"
date: "12 July, 2022"
output:
  html_document:
    code_folding: hide
    css: src/style.css
    theme: united
    highlight: tango
    includes:
      in_header: src/header.html
nocite: "@*"
csl: src/apa.csl
bibliography: src/references.bib
---

***

![Photo by <a href="https://unsplash.com\@harashog?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Sarah G.</a> on <a href="https://unsplash.com/s/photos/confused-dog?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>](img/header.jpg)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, out.width = "100%", message = FALSE, warning = FALSE)
```

```{r get_data, include=FALSE}
# Package names
packages <- c("dplyr", "readr", "ggplot2", "coronavirus", "plotly", "gtrendsR", "medrxivr", "pageviews", "scales")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))

# Update the dataset from coronavirus package to get newest stats
update_dataset(silence = TRUE)

# Define constant variables
discrete_palette <- c("#e60049", "#0bb4ff", "#9b19f5", "#ffa300", "#dc0ab4", "#b3d4ff", "#00bfa0")
start_date <- as.Date("2020-01-01")
end_date <- as.Date("2022-07-01")

# Coronavirus cases -------------------------------------------------------

# Summarize the data to get weekly new Covid cases for all countries combined
monthly_cases <- coronavirus %>%
  filter(type == "confirmed" & date < end_date) %>%
  mutate(month = as.Date(cut(date, breaks = "months", start.on.monday = TRUE))) %>%
  group_by(month) %>%
  summarise(million_new_cases = round(sum(cases) / 1000000, 3))

# Repeat the same for continents
monthly_cases_continent <- coronavirus %>%
  filter(type == "confirmed" & date < end_date & !is.na(continent_name)) %>%
  mutate(
    month = as.Date(cut(date, breaks = "months", start.on.monday = TRUE)),
    continent_name = as.factor(continent_name)
  ) %>%
  group_by(month, continent_name) %>%
  summarise(million_new_cases = round(sum(cases) / 1000000, 3))

# Google Trends -----------------------------------------------------------

# Extract Google Trends data using the gtrendsR package
gtrends <- gtrends(
  keyword = "long covid",
  geo = "",
  time = paste(start_date, end_date),
  gprop = "web",
  onlyInterest = TRUE
) %>%
  .[["interest_over_time"]] %>%
  transmute(
    month = as.Date(cut(as.Date(date) + 1, breaks = "months", start.on.monday = TRUE)),
    hits = as.numeric(replace(hits, hits == "<1", "0"))
  ) %>%
  group_by(month) %>%
  summarise(monthly_n = sum(hits))

# Visits to Wikipedia article ---------------------------------------------

# Extract data for visits of "Long Covid" Wiki page from human users with pageviews package
wiki <- article_pageviews(
  project = "en.wikipedia",
  article = "Long_COVID",
  user_type = "user",
  start = pageview_timestamps(start_date),
  end = pageview_timestamps(end_date),
  granularity = "daily"
) %>%
  transmute(
    month = as.Date(cut(as.Date(date) + 1, breaks = "months", start.on.monday = TRUE)),
    views = as.numeric(views)
  ) %>%
  group_by(month) %>%
  summarise(monthly_n = sum(views))


# Preprints in the medRxiv database --------------------------------------

# Import the medRxiv database from a cached snapshot
preprint_data <- mx_snapshot()

# Get cumulative counts
medrxiv <- mx_search(
  data = preprint_data,
  fields = c("title", "abstract"),
  auto_caps = TRUE,
  query = c(
    "long covid",
    "long Covid",
    "long COVID",
    "long-COVID",
    "long COVID-19",
    "long Covid-19",
    "post-COVID",
    "post COVID",
    "post-COVID-19",
    "post-covid-19",
    "post-Covid-19"
  )
) %>%
  filter(date < end_date) %>%
  mutate(month = as.Date(cut(as.Date(date), breaks = "months", start.on.monday = TRUE))) %>%
  count(month, name = "monthly_n") %>%
  ungroup()

# Combine Google Trends, Wikipedia views and Preprints -------------------
combined_data <- bind_rows(list(
  "Google" = gtrends,
  "Wikipedia" = wiki,
  "medRxiv" = medrxiv
),
.id = "data_source"
) %>%
  filter(month < end_date) %>%
  group_by(data_source) %>%
  mutate(monthly_n_scaled = round(rescale(monthly_n, to = c(0, 100)))) %>%
  ungroup()
```

> *Note to reader: This blog post is a project for the Science Communication Laboratories course at the University of Vienna. The simulated Q&A format between an "expert" and a member of the public was inspired by an article at* [Krautreporter](https://krautreporter.de/4299-quantencomputer-verstandlich-erklart)*. The graphs presented in this article are produced in a fully reproducible programmatic way. You can see the script by clicking on a particulate "code" label. Furthermore, the complete source code of this project is available in a [GitHub repository](https://github.com/opop999/sci_comm_long_covid%22).*

***

### It seems that we keep hearing about Long Covid more and more... <br><br> Perhaps we have somebody in our surrounding that suffer from it... <br><br> This post looks more closely at the public and scientific interest in this topic.

<br>

#### **Q: Okay, hold on. What actually is Long Covid?**

As of mid-2022, *Long Covid* (or *post-COVID syndrome*) is far from fully understood, and its research is constantly in flux. For instance, [CDC's](https://www.cdc.gov/coronavirus/2019-ncov/long-term-effects/index.html) website lists potential symptoms people can experience without testing positive for Covid-19: tiredness, chronic cough, and "brain fog," among many others. These symptoms can last for months and possibly years - it is simply too soon to say.

<br>

#### **Q: That sound unpleasant! How many people does it affect?**

First, let's discuss how to get the most reliable answer to a scientific question, which is even more critical for phenomena like Long Covid, which are developing as we speak (or write). Unfortunately, individual studies can sometimes paint a wildly inaccurate picture of reality. This can be due to many reasons, such as inappropriate methodology, a small research sample, or a stroke of pure bad luck!

For this reason, scientists prefer consulting "studies of studies," better known as *meta-analyses* or *systematic reviews*. The most recent one (April 2022) on this question, from @chen2022, suggests that there might be around 200 million people globally affected by Long Covid! As shown in the graphic below, while Covid cases are down from their peak in the first quarter of 2022, at least 15 million people are infected monthly. Unfortunately, this means that the 200 million figure is probably not the ceiling... 

```{r plot_covid_world}
# Graph for all Covid-19 cases worldwide ----------------------------------

(monthly_cases %>%
  ggplot(aes(x = month, y = million_new_cases)) +
  geom_line(color = "#1A53FF") +
  geom_point(size = 0.3, color = "#1A53FF") +
  ylab(element_blank()) +
  xlab(element_blank()) +
  labs(title = "Monthly confirmed COVID-19 cases, globally (in million)") +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text = element_text(size = 7),
    plot.background = element_rect(fill = "#FAF8FF"),
    plot.title = element_text(face = "bold", size = 14),
    axis.title.y = element_text(size = 8),
    legend.text = element_text(size = 9),
    legend.key = element_rect(fill = NA),
    legend.background = element_rect(fill = NA),
    plot.margin = margin(10, 20, 22, 5, "pt")
  ) +
  labs(color = "") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%y") +
  scale_y_continuous(
    expand = c(0, 0),
    breaks = seq(0, 100, 10),
    labels = seq(0, 100, 10),
    limits = c(0, max(monthly_cases$million_new_cases) + 10)
  )
) %>%
  ggplotly() %>%
  layout(
    annotations =
      list(
        x = 1,
        y = -0.16,
        text = "Data: Dong et al., 2020",
        showarrow = FALSE,
        xref = "paper",
        yref = "paper",
        font = list(size = 10)
      )
  )
```

<br>

#### **Q: I see. But let's rewind the time a bit. How did Long Covid even enter our social media feeds and daily vocabulary?**

That is not a trivial question to answer. It depends on the angle we look. To even try, we need to establish some common baseline. We are talking about the concept of Long Covid as it exists in English. Since you are reading this article in English, there is a higher chance you come from a country where English is the majority language. We can thus suppose that the public interest in the "Long Covid" (and not "ロングコビッド") will not be equally geographically distributed. 

However, the same applies to Covid-19 itself. If you look at the graphic below, you might find it quite different from the previous one - the number of confirmed cases sometimes varies enormously from continent to continent (although Q1 2022 was the worst for each continent, except for Oceania). So, this is something to keep in mind when interpreting the data further.


```{r plot_covid_continent}
# Graph for all Covid-19 cases by continent -------------------------------

(
  monthly_cases_continent %>%
    ggplot(aes(x = month, y = million_new_cases, color = continent_name)) +
    geom_line() +
    geom_point(size = 0.3) +
    ylab(element_blank()) +
    xlab(element_blank()) +
    scale_colour_manual(values = discrete_palette) +
    labs(title = "Monthly confirmed COVID-19 cases, by continent (in million)") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      axis.text = element_text(size = 7),
      plot.background = element_rect(fill = "#FAF8FF"),
      plot.title = element_text(face = "bold", size = 14),
      axis.title.y = element_text(size = 8),
      legend.text = element_text(size = 9),
      legend.key = element_rect(fill = NA),
      legend.background = element_rect(fill = NA),
      plot.margin = margin(10, 20, 22, 5, "pt")
    ) +
    labs(color = "") +
    scale_x_date(date_breaks = "1 month", date_labels = "%b-%y") +
    scale_y_continuous(
      expand = c(0, 0),
      breaks = seq(0, 100, 5),
      labels = seq(0, 100, 5),
      limits = c(0, max(monthly_cases_continent$million_new_cases) + 5)
    )
) %>%
  ggplotly() %>%
  layout(
    annotations =
      list(
        x = 1,
        y = -0.16,
        text = "Data: Dong et al., 2020",
        showarrow = FALSE,
        xref = "paper",
        yref = "paper",
        font = list(size = 10)
      )
  )
```

<br>

#### **Q: You seem to suggest that the attention to Long Covid is unequal. Other than continents, can you give me a concrete example?**

If only there were a single measure of public interest in some topic! Since this is not the case, we must make our way around it and use what scientists call "triangulation." In plain language, it means measuring some phenomena, combining multiple methods and data sources to increase the reliability of our findings (similar logic to the *meta-analyses* we discussed previously). 

In practice, we can use tools such as Google Trends to answer the question of public attention to Long Covid, which gives us information about the intensity of interest in some search terms over time. We can then "triangulate" it with data from Wikipedia, which gives us information on how many people viewed a Long Covid page.

As you can see in the graph below - the Long Covid Wiki page only first appeared in the second half of 2020; however, the intensity of its visits seems to have correlated with Google Trends. Intuitively this is probably not too surprising - if we Google for a specific term, a link to Wikipedia is one of the first we usually see. Nevertheless, this exercise is essential to us, as it lends some credibility to the data from Google searches.

If we look closer, we might see some prominent "peaks" of public interest in the subject. Winter 2020/2021 was probably when Long Covid first started being noticed by the wider English-speaking public. However, it seems to have been summer 2021 and winter 2021/2022 when the concept went mainstream.

```{r plot_gtrends_wiki_medrxiv}
# Graph combining intensity of interest in Long Covid topic ---------------

(
  combined_data %>%
    ggplot(aes(x = month, y = monthly_n_scaled, color = data_source)) +
    geom_line() +
    geom_point(size = 0.3) +
    ylab(element_blank()) +
    xlab(element_blank()) +
    scale_colour_manual(values = discrete_palette) +
    labs(title = "Relative Interest in Long Covid Through Time: <br> Wikipedia, Google Trends and medrXiv preprints") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      axis.text = element_text(size = 7),
      plot.background = element_rect(fill = "#FAF8FF"),
      plot.title = element_text(face = "bold", size = 11),
      axis.title.y = element_text(size = 8),
      legend.text = element_text(size = 9),
      legend.key = element_rect(fill = NA),
      legend.background = element_rect(fill = NA),
      plot.margin = margin(10, 20, 22, 5, "pt")
    ) +
    labs(color = "") +
    scale_x_date(date_breaks = "1 month", date_labels = "%b-%y") +
    scale_y_continuous(
      expand = c(0, 0),
      breaks = seq(0, 100, 10),
      labels = paste(seq(0, 100, 10), "%"),
      limits = c(0, max(combined_data$monthly_n_scaled) + 10)
    )

) %>%
  ggplotly() %>%
  layout(
    annotations =
      list(
        x = 1,
        y = -0.16,
        text = "Source: Wikipedia (visits to English-version Long Covid page), Google Trends (global Long Covid search intensity) & medRxiv (number of published preprints on Long Covid). Data scaled to fit between 0-100% within each source.",
        showarrow = FALSE,
        xref = "paper",
        yref = "paper",
        font = list(size = 5)
      )
  )
```

<br>

#### **Q: There is something strange here. How can we explain the peak of interest in the mid-2021, given that cases were relatively lower?**

Excellent graph-looking! Indeed, this is a perfect example of why we hear scientists say that "correlation is not causation." While we might associate the interest in Long Covid with Covid-19 cases, many factors could be in play. One of them might be media coverage of Long Covid. 

While "normal" scientific processes, such as peer-review of journal articles, take much time, the Covid-19 pandemic has been fast-evolving. To deal with this, researchers extensively used *preprint* articles, published shortly after study completion and without peer review. One of the most central repositories of these medical preprints is medrXiv. 

These preprints have not only been read by other scientists but also by media outlets. As a study (peer-reviewed, for that matter) of @fleerackers2022 finds, the usage of evidence from media's preprints has often been troubling. Outlets frequently "forget" to mention that their source is a preprint and that the findings should thus be viewed very carefully. In some cases, as the data journalist Aleszu Bajak and his colleagues [write in NYT](https://www.nytimes.com/2020/05/14/opinion/coronavirus-research-misinformation.html), preprints became "weaponized". One particular preprint from April 2020 went viral on social media to provide an argument for opponents of social mitigation efforts to contain Covid-19.    

If we look at the intensity of research interest in Long Covid, as measured by medrXiv preprints, it would seem that there was an early peak in autumn 2020, which preceded the public interest in the subsequent winter period.

<br>

#### **Q: Does that mean we can prove that preprints are first picked up by media, which in turn get people interested in Long Covid?**

While this is a relative intuitive explanation and there are some hints from recent studies that this might be the case, we have to be again very careful.
For instance, what about the seeming disconnect between preprints and Google/Wiki data since the beginning of 2022? To better disentangle this, we would need to look closer and give fair evaluation to other data sources and explanations.

<br>

#### Summing up: <br><br> Scientific work might be part art and part luck, but a significant part of the process still consists of a thorough detective-like job, which includes regular questioning of our pre-existing beliefs and openness to the change of opinion. <br> <br> This is no different when it comes to the Long Covid subject. 

<br> 

***

#### **References**

