---
title: "Long Covid:"
subtitle: "What is the buzz all about?"
author: "Ondrej Pekacek"
date: "12 July, 2022"
output:
  html_document:
    code_folding: hide
    css: src/style.css
    theme: united
    highlight: tango
    includes:
      in_header: src/header.html
nocite: "@*"
csl: src/apa.csl
bibliography: src/references.bib
---

***

![Photo by <a href="https://unsplash.com\@harashog?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Sarah G.</a> on <a href="https://unsplash.com/s/photos/confused-dog?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>](img/header.jpg)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, out.width = "100%", message = FALSE, warning = FALSE)
```

```{r get_data, eval=FALSE, include=FALSE}
# Package names
packages <- c("dplyr", "readr", "ggplot2", "coronavirus", "plotly", "gtrendsR", "medrxivr", "pageviews", "scales")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))

# Update the dataset from coronavirus package to get newest stats
update_dataset(silence = TRUE)

# Define constant variables
discrete_palette <- c("#e60049", "#0bb4ff", "#9b19f5", "#ffa300", "#dc0ab4", "#b3d4ff", "#00bfa0")
start_date <- as.Date("2020-01-01")
end_date <- as.Date("2022-07-01")

# Coronavirus cases -------------------------------------------------------

# Summarize the data to get weekly new Covid cases for all countries combined
monthly_cases <- coronavirus %>%
  filter(type == "confirmed" & date < end_date) %>%
  mutate(month = as.Date(cut(date, breaks = "months", start.on.monday = TRUE))) %>%
  group_by(month) %>%
  summarise(million_new_cases = round(sum(cases) / 1000000, 3))

# Repeat the same for continents
monthly_cases_continent <- coronavirus %>%
  filter(type == "confirmed" & date < end_date & !is.na(continent_name)) %>%
  mutate(
    month = as.Date(cut(date, breaks = "months", start.on.monday = TRUE)),
    continent_name = as.factor(continent_name)
  ) %>%
  group_by(month, continent_name) %>%
  summarise(million_new_cases = round(sum(cases) / 1000000, 3))

# Google Trends -----------------------------------------------------------

# Extract Google Trends data using the gtrendsR package
gtrends <- gtrends(
  keyword = "long covid",
  geo = "",
  time = paste(start_date, end_date),
  gprop = "web",
  onlyInterest = TRUE
) %>%
  .[["interest_over_time"]] %>%
  transmute(
    month = as.Date(cut(as.Date(date) + 1, breaks = "months", start.on.monday = TRUE)),
    hits = as.numeric(replace(hits, hits == "<1", "0"))
  ) %>%
  group_by(month) %>%
  summarise(monthly_n = sum(hits))

# Visits to Wikipedia article ---------------------------------------------

# Extract data for visits of "Long Covid" Wiki page from human users with pageviews package
wiki <- article_pageviews(
  project = "en.wikipedia",
  article = "Long_COVID",
  user_type = "user",
  start = pageview_timestamps(start_date),
  end = pageview_timestamps(end_date),
  granularity = "daily"
) %>%
  transmute(
    month = as.Date(cut(as.Date(date) + 1, breaks = "months", start.on.monday = TRUE)),
    views = as.numeric(views)
  ) %>%
  group_by(month) %>%
  summarise(monthly_n = sum(views))


# Pre-Prints in the medRxiv database --------------------------------------

# Import the medRxiv database from a cached snapshot
preprint_data <- mx_snapshot()

# Get cumulative counts
medrxiv <- mx_search(
  data = preprint_data,
  fields = c("title", "abstract"),
  auto_caps = TRUE,
  query = c(
    "long covid",
    "long Covid",
    "long COVID",
    "long-COVID",
    "long COVID-19",
    "long Covid-19",
    "post-COVID",
    "post COVID",
    "post-COVID-19",
    "post-covid-19",
    "post-Covid-19"
  )
) %>%
  filter(date < end_date) %>%
  mutate(month = as.Date(cut(as.Date(date), breaks = "months", start.on.monday = TRUE))) %>%
  count(month, name = "monthly_n") %>%
  ungroup()

# Combine Google Trends, Wikipedia views and Pre-Prints -------------------
combined_data <- bind_rows(list(
  "Google" = gtrends,
  "Wikipedia" = wiki,
  "medRxiv" = medrxiv
),
.id = "data_source"
) %>%
  filter(month < end_date) %>%
  group_by(data_source) %>%
  mutate(monthly_n_scaled = round(rescale(monthly_n, to = c(0, 100)))) %>%
  ungroup()
```

> *Note to reader: This blog post is a project for the Science Communication Laboratories course at the University of Vienna. The simulated Q&A format between an "expert" and a member of the public was inspired by an article at* [Krautreporter](https://krautreporter.de/4299-quantencomputer-verstandlich-erklart)*. The graphs presented in this article are produced in a fully reproducible programmatic way. You can see the script by clicking on a particulate "code" label. Furthermore, the complete source code of this project is available in a [GitHub repository](https://github.com/opop999/sci_comm_long_covid%22).*

***

### It seems that we keep hearing about Long Covid more and more... <br> Perhaps we have somebody in our surrounding that suffer with it... <br> This blog post will try to look more closely at this concept and the public and scientific interest in it.

<br>

#### **Q: Okay, hold on. What actually is Long Covid?**

As of mid-2022, *Long Covid* (or *post-COVID syndrome*) is far from fully understood, and its research is constantly in flux. For instance, [CDC's](https://www.cdc.gov/coronavirus/2019-ncov/long-term-effects/index.html) website lists potential symptoms people can experience without testing positive for COVID-19: tiredness, chronic cough, and "brain fog," among many others. These symptoms can last for months and possibly years - it is simply too soon to say.

<br>

#### **Q: That sound unpleasant! How many people does it affect?**

First, let's discuss how to get the most reliable answer to a scientific question, which is even more critical for phenomena like Long Covid, which are developing as we speak (or write). Unfortunately, individual studies can sometimes paint a wildly inaccurate picture of reality. This can be due to many reasons, such as inappropriate methodology, a small research sample, or a stroke of pure bad luck!

For this reason, scientists prefer consulting "studies of studies," better known as *meta-analyses* or *systematic reviews*. The most recent one (April 2022) on this question, from @chen2022, suggests that there might be around 200 million people globally affected by Long Covid! As shown in the graphic below, while Covid cases are down from their peak in the first quarter of 2022, at least 15 million people are infected monthly. Unfortunately, this means that the 200 million figure is probably not the ceiling... 

```{r plot_covid_world}
# Graph for all Covid-19 cases worldwide ----------------------------------

(monthly_cases %>%
  ggplot(aes(x = month, y = million_new_cases)) +
  geom_line(color = "#1A53FF") +
  geom_point(size = 0.3, color = "#1A53FF") +
  ylab(element_blank()) +
  xlab(element_blank()) +
  labs(title = "Monthly confirmed COVID-19 cases, globally (in million)") +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text = element_text(size = 7),
    plot.background = element_rect(fill = "#FAF8FF"),
    plot.title = element_text(face = "bold", size = 14),
    axis.title.y = element_text(size = 8),
    legend.text = element_text(size = 9),
    legend.key = element_rect(fill = NA),
    legend.background = element_rect(fill = NA),
    plot.margin = margin(10, 20, 22, 5, "pt")
  ) +
  labs(color = "") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b-%y") +
  scale_y_continuous(
    expand = c(0, 0),
    breaks = seq(0, 100, 10),
    labels = seq(0, 100, 10),
    limits = c(0, max(monthly_cases$million_new_cases) + 10)
  )
) %>%
  ggplotly() %>%
  layout(
    annotations =
      list(
        x = 1,
        y = -0.16,
        text = "Data: Dong et al., 2020",
        showarrow = FALSE,
        xref = "paper",
        yref = "paper",
        font = list(size = 10)
      )
  )
```

<br>

#### **Q: I see. But let's rewind the time a bit. How did Long Covid even enter our social media feeds and daily vocabulary?**

That is not a trivial question to answer. It depends on the angle we look. To even try, we need to establish some common baseline. We are talking about the concept of Long Covid as it exists in English. Since you are reading this article in English, there is a higher chance you come from a country where English is the majority language. We can thus suppose that the public interest in the "Long Covid" (and not "ロングコビッド") will not be equally geographically distributed. 

However, the same applies to COVID-19 itself. If you look at the graphic below, you might find it quite different from the previous one - the number of confirmed cases sometimes varies enormously from continent to continent (although Q1 2022 was the worst for each continent, except for Oceania). So, this is something to keep in mind when interpreting the data further.


```{r plot_covid_continent}
# Graph for all Covid-19 cases by continent -------------------------------

(
  monthly_cases_continent %>%
    ggplot(aes(x = month, y = million_new_cases, color = continent_name)) +
    geom_line() +
    geom_point(size = 0.3) +
    ylab(element_blank()) +
    xlab(element_blank()) +
    scale_colour_manual(values = discrete_palette) +
    labs(title = "Monthly confirmed COVID-19 cases, by continent (in million)") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      axis.text = element_text(size = 7),
      plot.background = element_rect(fill = "#FAF8FF"),
      plot.title = element_text(face = "bold", size = 14),
      axis.title.y = element_text(size = 8),
      legend.text = element_text(size = 9),
      legend.key = element_rect(fill = NA),
      legend.background = element_rect(fill = NA),
      plot.margin = margin(10, 20, 22, 5, "pt")
    ) +
    labs(color = "") +
    scale_x_date(date_breaks = "1 month", date_labels = "%b-%y") +
    scale_y_continuous(
      expand = c(0, 0),
      breaks = seq(0, 100, 5),
      labels = seq(0, 100, 5),
      limits = c(0, max(monthly_cases_continent$million_new_cases) + 5)
    )
) %>%
  ggplotly() %>%
  layout(
    annotations =
      list(
        x = 1,
        y = -0.16,
        text = "Data: Dong et al., 2020",
        showarrow = FALSE,
        xref = "paper",
        yref = "paper",
        font = list(size = 10)
      )
  )
```

<br>

#### **Q: You seem to suggest that the attention to Long Covid is unequal. Other than continents, can you give me a concrete example?**

If only there was a single measure of public interest in some topic! Since this is not the case, we need to make our way around it and use what scientists call "triangulation". In plain language, it means that to measure some phenomena, we need to combine multiple methods and/or data sources, to increase the reliability of our findings (similar logic to *meta-analyses* we discussed previously). 

In practice, to answer the question of public attention to Long Covid, we can use tools such as Google Trends, which gives us information about an intensity of interest in some search term over time. We can then "triangulate" it with data from Wikipedia, which gives us information of how many people viewed a Long Covid page.

As you can see in the graph below - Long Covid Wiki page only first appeared in second half of 2020, however, the intensity of its visits seem to have correlated with Google Trends. Intuitively this is probably not to surprising - if we Google for a specific term, link to Wikipedia is one of the first we usually see. Nevertheless, this exercise is important to us, as it lends some credibility to the data from Google searches.

If we look closer, we might see some prominent "peaks" of public interest in the subject. Winter 2020/2021 was probably the period when Long Covid first started being noticed by wider English-speaking public. However, it seems to have been summer 2021 and winter 2021/2022 when the concept truly went mainstream.

<br>

```{r plot_gtrends_wiki_medrxiv}
# Graph combining intensity of interest in Long Covid topic ---------------

(
  combined_data %>%
    ggplot(aes(x = month, y = monthly_n_scaled, color = data_source)) +
    geom_line() +
    geom_point(size = 0.3) +
    ylab(element_blank()) +
    xlab(element_blank()) +
    scale_colour_manual(values = discrete_palette) +
    labs(title = "Relative Interest in Long Covid Through Time: <br> Wikipedia, Google Trends and Pre-Prints") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      axis.text = element_text(size = 7),
      plot.background = element_rect(fill = "#FAF8FF"),
      plot.title = element_text(face = "bold", size = 11),
      axis.title.y = element_text(size = 8),
      legend.text = element_text(size = 9),
      legend.key = element_rect(fill = NA),
      legend.background = element_rect(fill = NA),
      plot.margin = margin(10, 20, 22, 5, "pt")
    ) +
    labs(color = "") +
    scale_x_date(date_breaks = "1 month", date_labels = "%b-%y") +
    scale_y_continuous(
      expand = c(0, 0),
      breaks = seq(0, 100, 10),
      labels = paste(seq(0, 100, 10), "%"),
      limits = c(0, max(combined_data$monthly_n_scaled) + 10)
    )

) %>%
  ggplotly() %>%
  layout(
    annotations =
      list(
        x = 1,
        y = -0.16,
        text = "Source: Wikipedia (visits to English-version Long Covid page), Google Trends (global Long Covid search intensity) & medRxiv (number of published pre-prints on Long Covid). Data scaled to fit between 0-100% within each source.",
        showarrow = FALSE,
        xref = "paper",
        yref = "paper",
        font = list(size = 5)
      )
  )
```

<br> 

***

#### **References**

